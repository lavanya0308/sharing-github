{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Introduction\n",
    "What is Pandas?\n",
    "\n",
    "Pandas is a Python library used for working with data sets.\n",
    "\n",
    "It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
    "\n",
    "The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008.\n",
    "\n",
    "Why Use Pandas?\n",
    "\n",
    "Pandas allows us to analyze big data and make conclusions based on statistical theories.\n",
    "\n",
    "Pandas can clean messy data sets, and make them readable and relevant.\n",
    "\n",
    "Relevant data is very important in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Can Pandas Do?\n",
    "Pandas gives you answers about the data. Like:\n",
    "\n",
    "Is there a correlation between two or more columns?\n",
    "\n",
    "What is average value?\n",
    "\n",
    "Max value?\n",
    "\n",
    "Min value?\n",
    "\n",
    "Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cars  passings\n",
      "0    BMW         3\n",
      "1  Volvo         7\n",
      "2   Ford         2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "mydataset = {\n",
    "  'cars': [\"BMW\", \"Volvo\", \"Ford\"],\n",
    "  'passings': [3, 7, 2]\n",
    "}\n",
    "\n",
    "myvar = pandas.DataFrame(mydataset)\n",
    "\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Series\n",
    "What is a Series?\n",
    "A Pandas Series is like a column in a table.\n",
    "\n",
    "It is a one-dimensional array holding data of any type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple Pandas Series from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    7\n",
      "2    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = [1, 7, 2]\n",
    "myvar = pd.Series(a)\n",
    "print(myvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels\n",
    "If nothing else is specified, the values are labeled with their index number. First value has index 0, second value has index 1 etc.\n",
    "\n",
    "This label can be used to access a specified value.\n",
    "\n",
    "Return the first value of the Series:print(myvar[0])\n",
    "    \n",
    "Create Labels\n",
    "\n",
    "With the index argument, you can name your own labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x    1\n",
      "y    7\n",
      "z    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = [1, 7, 2]\n",
    "myvar = pd.Series(a, index = [\"x\", \"y\", \"z\"])\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key/Value Objects as Series\n",
    "You can also use a key/value object, like a dictionary, when creating a Series.\n",
    "\n",
    "Create a simple Pandas Series from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day1    420\n",
      "day2    380\n",
      "day3    390\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "myvar = pd.Series(calories)\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "Data sets in Pandas are usually multi-dimensional tables, called DataFrames.\n",
    "\n",
    "Series is like a column, a DataFrame is the whole table.\n",
    "\n",
    "Create a DataFrame from two Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories  duration\n",
      "0       420        50\n",
      "1       380        40\n",
      "2       390        45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "  \"calories\": [420, 380, 390],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "\n",
    "myvar = pd.DataFrame(data)\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a DataFrame?\n",
    "A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, or a table with rows and columns.\n",
    "\n",
    "Create a simple Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories  duration\n",
      "0       420        50\n",
      "1       380        40\n",
      "2       390        45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "  \"calories\": [420, 380, 390],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "\n",
    "#load data into a DataFrame object:\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate Row\n",
    "As you can see from the result above, the DataFrame is like a table with rows and columns.\n",
    "\n",
    "Pandas use the loc attribute to return one or more specified row(s)\n",
    "\n",
    "Return row 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calories    420\n",
      "duration     50\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories  duration\n",
      "0       420        50\n",
      "1       380        40\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[[0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Indexes\n",
    "With the index argument, you can name your own indexes.\n",
    "\n",
    "Add a list of names to give each row a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      calories  duration\n",
      "day1       420        50\n",
      "day2       380        40\n",
      "day3       390        45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "  \"calories\": [420, 380, 390],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "df = pd.DataFrame(data, index = [\"day1\", \"day2\", \"day3\"])\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate Named Indexes\n",
    "Use the named index in the loc attribute to return the specified row(s).\n",
    "\n",
    "Return \"day2\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calories    380\n",
      "duration     40\n",
      "Name: day2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[\"day2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files Into a DataFrame\n",
    "If your data sets are stored in a file, Pandas can load them into a DataFrame.\n",
    "\n",
    "Load a comma separated file (CSV file) into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YearsExperience    Salary\n",
      "0               1.1   39343.0\n",
      "1               1.3   46205.0\n",
      "2               1.5   37731.0\n",
      "3               2.0   43525.0\n",
      "4               2.2   39891.0\n",
      "5               2.9   56642.0\n",
      "6               3.0   60150.0\n",
      "7               3.2   54445.0\n",
      "8               3.2   64445.0\n",
      "9               3.7   57189.0\n",
      "10              3.9   63218.0\n",
      "11              4.0   55794.0\n",
      "12              4.0   56957.0\n",
      "13              4.1   57081.0\n",
      "14              4.5   61111.0\n",
      "15              4.9   67938.0\n",
      "16              5.1   66029.0\n",
      "17              5.3   83088.0\n",
      "18              5.9   81363.0\n",
      "19              6.0   93940.0\n",
      "20              6.8   91738.0\n",
      "21              7.1   98273.0\n",
      "22              7.9  101302.0\n",
      "23              8.2  113812.0\n",
      "24              8.7  109431.0\n",
      "25              9.0  105582.0\n",
      "26              9.5  116969.0\n",
      "27              9.6  112635.0\n",
      "28             10.3  122391.0\n",
      "29             10.5  121872.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//Salary_Data.csv')\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Analyzing DataFrames\n",
    "Viewing the Data\n",
    "One of the most used method for getting a quick overview of the DataFrame, is the head() method.\n",
    "\n",
    "The head() method returns the headers and a specified number of rows, starting from the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a quick overview by printing the first 10 rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YearsExperience   Salary\n",
      "0              1.1  39343.0\n",
      "1              1.3  46205.0\n",
      "2              1.5  37731.0\n",
      "3              2.0  43525.0\n",
      "4              2.2  39891.0\n",
      "5              2.9  56642.0\n",
      "6              3.0  60150.0\n",
      "7              3.2  54445.0\n",
      "8              3.2  64445.0\n",
      "9              3.7  57189.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//Salary_Data.csv')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the last 5 rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YearsExperience    Salary\n",
      "25              9.0  105582.0\n",
      "26              9.5  116969.0\n",
      "27              9.6  112635.0\n",
      "28             10.3  122391.0\n",
      "29             10.5  121872.0\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info About the Data\n",
    "The DataFrames object has a method called info(), that gives you more information about the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 2 columns):\n",
      "YearsExperience    30 non-null float64\n",
      "Salary             30 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 560.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Cleaning Data\n",
    "\n",
    "Data cleaning means fixing bad data in your data set.\n",
    "\n",
    "Bad data could be:\n",
    "\n",
    "Empty cells\n",
    "\n",
    "Data in wrong format\n",
    "\n",
    "Wrong data\n",
    "\n",
    "Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Cleaning Empty Cells\n",
    "\n",
    "Empty cells can potentially give you a wrong result when you analyze data.\n",
    "\n",
    "Remove Rows\n",
    "\n",
    "One way to deal with empty cells is to remove rows that contain empty cells.\n",
    "\n",
    "This is usually OK, since data sets can be very big, and removing a few rows will not have a big impact on the result.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a new Data Frame with no empty cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Duration          Date  Pulse  Maxpulse  Calories\n",
      "0         60  '2020/12/01'    110       130     409.1\n",
      "1         60  '2020/12/02'    117       145     479.0\n",
      "2         60  '2020/12/03'    103       135     340.0\n",
      "3         45  '2020/12/04'    109       175     282.4\n",
      "4         45  '2020/12/05'    117       148     406.0\n",
      "5         60  '2020/12/06'    102       127     300.0\n",
      "6         60  '2020/12/07'    110       136     374.0\n",
      "7        450  '2020/12/08'    104       134     253.3\n",
      "8         30  '2020/12/09'    109       133     195.1\n",
      "9         60  '2020/12/10'     98       124     269.0\n",
      "10        60  '2020/12/11'    103       147     329.3\n",
      "11        60  '2020/12/12'    100       120     250.7\n",
      "12        60  '2020/12/12'    100       120     250.7\n",
      "13        60  '2020/12/13'    106       128     345.3\n",
      "14        60  '2020/12/14'    104       132     379.3\n",
      "15        60  '2020/12/15'     98       123     275.0\n",
      "16        60  '2020/12/16'     98       120     215.2\n",
      "17        60  '2020/12/17'    100       120     300.0\n",
      "19        60  '2020/12/19'    103       123     323.0\n",
      "20        45  '2020/12/20'     97       125     243.0\n",
      "21        60  '2020/12/21'    108       131     364.2\n",
      "23        60  '2020/12/23'    130       101     300.0\n",
      "24        45  '2020/12/24'    105       132     246.0\n",
      "25        60  '2020/12/25'    102       126     334.5\n",
      "26        60      20201226    100       120     250.0\n",
      "27        60  '2020/12/27'     92       118     241.0\n",
      "29        60  '2020/12/29'    100       132     280.0\n",
      "30        60  '2020/12/30'    102       129     380.3\n",
      "31        60  '2020/12/31'     92       115     243.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "new_df = df.dropna()\n",
    "print(new_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to change the original DataFrame, use the inplace = True argument:\n",
    "\n",
    "Remove all rows with NULL values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Duration          Date  Pulse  Maxpulse  Calories\n",
      "0         60  '2020/12/01'    110       130     409.1\n",
      "1         60  '2020/12/02'    117       145     479.0\n",
      "2         60  '2020/12/03'    103       135     340.0\n",
      "3         45  '2020/12/04'    109       175     282.4\n",
      "4         45  '2020/12/05'    117       148     406.0\n",
      "5         60  '2020/12/06'    102       127     300.0\n",
      "6         60  '2020/12/07'    110       136     374.0\n",
      "7        450  '2020/12/08'    104       134     253.3\n",
      "8         30  '2020/12/09'    109       133     195.1\n",
      "9         60  '2020/12/10'     98       124     269.0\n",
      "10        60  '2020/12/11'    103       147     329.3\n",
      "11        60  '2020/12/12'    100       120     250.7\n",
      "12        60  '2020/12/12'    100       120     250.7\n",
      "13        60  '2020/12/13'    106       128     345.3\n",
      "14        60  '2020/12/14'    104       132     379.3\n",
      "15        60  '2020/12/15'     98       123     275.0\n",
      "16        60  '2020/12/16'     98       120     215.2\n",
      "17        60  '2020/12/17'    100       120     300.0\n",
      "19        60  '2020/12/19'    103       123     323.0\n",
      "20        45  '2020/12/20'     97       125     243.0\n",
      "21        60  '2020/12/21'    108       131     364.2\n",
      "23        60  '2020/12/23'    130       101     300.0\n",
      "24        45  '2020/12/24'    105       132     246.0\n",
      "25        60  '2020/12/25'    102       126     334.5\n",
      "26        60      20201226    100       120     250.0\n",
      "27        60  '2020/12/27'     92       118     241.0\n",
      "29        60  '2020/12/29'    100       132     280.0\n",
      "30        60  '2020/12/30'    102       129     380.3\n",
      "31        60  '2020/12/31'     92       115     243.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "df.dropna(inplace = True)\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Empty Values\n",
    "Another way of dealing with empty cells is to insert a new value instead.\n",
    "\n",
    "This way you do not have to delete entire rows just because of some empty cells.\n",
    "\n",
    "The fillna() method allows us to replace empty cells with a value:\n",
    "\n",
    "Replace NULL values with the number 130:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "df.fillna(130, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Only For a Specified Columns\n",
    "The example above replaces all empty cells in the whole Data Frame.\n",
    "\n",
    "To only replace empty values for one column, specify the column name for the DataFrame:\n",
    "\n",
    "Replace NULL values in the \"Calories\" columns with the number 130:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "df[\"Calories\"].fillna(130, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Using Mean, Median, or Mode\n",
    "A common way to replace empty cells, is to calculate the mean, median or mode value of the column.\n",
    "\n",
    "Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column:\n",
    "\n",
    "Calculate the MEAN, and replace any empty values with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "x = df[\"Calories\"].mean()\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the MEDIAN, and replace any empty values with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv('data.csv')\n",
    "x = df[\"Calories\"].median()\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Cleaning Data of Wrong Format\n",
    "Data of Wrong Format\n",
    "Cells with data of wrong format can make it difficult, or even impossible, to analyze data.\n",
    "\n",
    "To fix it, you have two options: remove the rows, or convert all cells in the columns into the same format.\n",
    "\n",
    "Convert Into a Correct Format\n",
    "In our Data Frame, we have two cells with the wrong format. Check out row 22 and 26, the 'Date' column should be a string that represents a date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to convert all cells in the 'Date' column into dates.\n",
    "\n",
    "Pandas has a to_datetime() method for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Duration       Date  Pulse  Maxpulse  Calories\n",
      "0         60 2020-12-01    110       130     409.1\n",
      "1         60 2020-12-02    117       145     479.0\n",
      "2         60 2020-12-03    103       135     340.0\n",
      "3         45 2020-12-04    109       175     282.4\n",
      "4         45 2020-12-05    117       148     406.0\n",
      "5         60 2020-12-06    102       127     300.0\n",
      "6         60 2020-12-07    110       136     374.0\n",
      "7        450 2020-12-08    104       134     253.3\n",
      "8         30 2020-12-09    109       133     195.1\n",
      "9         60 2020-12-10     98       124     269.0\n",
      "10        60 2020-12-11    103       147     329.3\n",
      "11        60 2020-12-12    100       120     250.7\n",
      "12        60 2020-12-12    100       120     250.7\n",
      "13        60 2020-12-13    106       128     345.3\n",
      "14        60 2020-12-14    104       132     379.3\n",
      "15        60 2020-12-15     98       123     275.0\n",
      "16        60 2020-12-16     98       120     215.2\n",
      "17        60 2020-12-17    100       120     300.0\n",
      "18        45 2020-12-18     90       112       NaN\n",
      "19        60 2020-12-19    103       123     323.0\n",
      "20        45 2020-12-20     97       125     243.0\n",
      "21        60 2020-12-21    108       131     364.2\n",
      "22        45        NaT    100       119     282.0\n",
      "23        60 2020-12-23    130       101     300.0\n",
      "24        45 2020-12-24    105       132     246.0\n",
      "25        60 2020-12-25    102       126     334.5\n",
      "26        60 2020-12-26    100       120     250.0\n",
      "27        60 2020-12-27     92       118     241.0\n",
      "28        60 2020-12-28    103       132       NaN\n",
      "29        60 2020-12-29    100       132     280.0\n",
      "30        60 2020-12-30    102       129     380.3\n",
      "31        60 2020-12-31     92       115     243.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Fixing Wrong Data\n",
    "Wrong Data\n",
    "\"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", it can just be wrong, like if someone registered \"199\" instead of \"1.99\".\n",
    "\n",
    "Sometimes you can spot wrong data by looking at the data set, because you have an expectation of what it should be.\n",
    "\n",
    "If you take a look at our data set, you can see that in row 7, the duration is 450, but for all the other rows the duration is between 30 and 60.\n",
    "\n",
    "It doesn't have to be wrong, but taking in consideration that this is the data set of someone's workout sessions, we conclude with the fact that this person did not work out in 450 minutes.\n",
    "\n",
    "How can we fix wrong values, like the one for \"Duration\" in row 7?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing Values\n",
    "One way to fix wrong values is to replace them with something else.\n",
    "\n",
    "In our example, it is most likely a typo, and the value should be \"45\" instead of \"450\", and we could just insert \"45\" in row 7:\n",
    "\n",
    "Set \"Duration\" = 45 in row 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[7, 'Duration'] = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small data sets you might be able to replace the wrong data one by one, but not for big data sets.\n",
    "\n",
    "To replace wrong data for larger data sets you can create some rules, e.g. set some boundaries for legal values, and replace any values that are outside of the boundaries.\n",
    "\n",
    "Loop through all values in the \"Duration\" column.\n",
    "\n",
    "If the value is higher than 120, set it to 120:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.loc[x, \"Duration\"] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Rows\n",
    "Another way of handling wrong data is to remove the rows that contains wrong data.\n",
    "\n",
    "This way you do not have to find out what to replace them with, and there is a good chance you do not need them to do your analyses.\n",
    "\n",
    "Delete rows where \"Duration\" is higher than 120:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.drop(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Removing Duplicates\n",
    "Discovering Duplicates\n",
    "Duplicate rows are rows that have been registered more than one time.\n",
    "\n",
    "By taking a look at our test data set, we can assume that row 11 and 12 are duplicates.\n",
    "\n",
    "To discover duplicates, we can use the duplicated() method.\n",
    "\n",
    "The duplicated() method returns a Boolean values for each row:\n",
    "\n",
    "Returns True for every row that is a duplicate, othwerwise False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12     True\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "19    False\n",
      "20    False\n",
      "21    False\n",
      "22    False\n",
      "23    False\n",
      "24    False\n",
      "25    False\n",
      "26    False\n",
      "27    False\n",
      "28    False\n",
      "29    False\n",
      "30    False\n",
      "31    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Duplicates\n",
    "To remove duplicates, use the drop_duplicates() method.\n",
    "\n",
    "Remove all duplicates:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Data Correlations\n",
    "Finding Relationships\n",
    "\n",
    "A great aspect of the Pandas module is the corr() method.\n",
    "\n",
    "The corr() method calculates the relationship between each column in your data set.\n",
    "\n",
    "Show the relationship between the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059452</td>\n",
       "      <td>-0.250033</td>\n",
       "      <td>0.356437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td>-0.059452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269672</td>\n",
       "      <td>0.506593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxpulse</th>\n",
       "      <td>-0.250033</td>\n",
       "      <td>0.269672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calories</th>\n",
       "      <td>0.356437</td>\n",
       "      <td>0.506593</td>\n",
       "      <td>0.344494</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Duration     Pulse  Maxpulse  Calories\n",
       "Duration  1.000000 -0.059452 -0.250033  0.356437\n",
       "Pulse    -0.059452  1.000000  0.269672  0.506593\n",
       "Maxpulse -0.250033  0.269672  1.000000  0.344494\n",
       "Calories  0.356437  0.506593  0.344494  1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Explained\n",
    "The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns.\n",
    "\n",
    "The number varies from -1 to 1.\n",
    "\n",
    "1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\n",
    "\n",
    "0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\n",
    "\n",
    "-0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down.\n",
    "\n",
    "0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will.\n",
    "\n",
    "Perfect Correlation:\n",
    "We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself.\n",
    "\n",
    "Good Correlation:\n",
    "\"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out.\n",
    "\n",
    "Bad Correlation:\n",
    "\"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
